# Hive-Reflex 2.0 æ¨¡å‹åŠ è½½å™¨ä½¿ç”¨æŒ‡å—

## ğŸ“– æ¦‚è¿°

æ¨¡å‹åŠ è½½å™¨æä¾›äº†ä» FLASH åŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹å¹¶æ‰§è¡Œæ¨ç†çš„å®Œæ•´åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ¨¡å‹

```bash
# å¯¼å‡º ONNX æ¨¡å‹
python reflex_net_v2.py --quantize

# ç¼–è¯‘ä¸º CIM ä»£ç 
python mlir_compiler/compile.py --model reflex_net_v2.onnx
```

### 2. æ‰“åŒ…æ¨¡å‹

```bash
# æ‰“åŒ…æƒé‡ä¸º FLASH æ ¼å¼
python tools/flash_model.py \
    --weights build/reflex_weights.bin \
    --output build/model.flash \
    --name "ReflexNetV2" \
    --input-size 12 \
    --output-size 1 \
    --hidden-size 16 \
    --has-lstm \
    --gen-script
```

### 3. çƒ§å½•åˆ°èŠ¯ç‰‡

```bash
# æ–¹æ³• 1: ä½¿ç”¨å®Œæ•´æ„å»ºè„šæœ¬ (æ¨è)
.\build-complete.ps1 -Flash

# æ–¹æ³• 2: æ‰‹åŠ¨çƒ§å½•
openocd -f interface/jlink.cfg -f target/riscv.cfg -f build/model.ocd
```

### 4. è¿è¡Œç¤ºä¾‹ç¨‹åº

```bash
# ç¼–è¯‘æ¨ç†ç¤ºä¾‹
make APP_SRCS=examples/example_reflex_inference.c

# çƒ§å½•å›ºä»¶
make flash
```

## ğŸ“‹ API ä½¿ç”¨ç¤ºä¾‹

### åŠ è½½æ¨¡å‹

```c
#include "model_loader.h"

// 1. å®šä¹‰æ¨¡å‹ç»“æ„
Model_t model;

// 2. ä» FLASH åŠ è½½
if (Model_LoadFromFlash(MODEL_REFLEX_V2, &model) != 0) {
    printf("åŠ è½½å¤±è´¥\n");
    return -1;
}

// 3. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
Model_PrintInfo(&model);

// 4. åŠ è½½åˆ° CIM SRAM
Model_LoadToCIM(&model, 0);  // Bank 0
```

### æ‰§è¡Œæ¨ç†

```c
// 1. åˆ›å»ºæ¨ç†ä¸Šä¸‹æ–‡
InferenceContext_t *ctx = Inference_CreateContext(&model);

// 2. å‡†å¤‡è¾“å…¥æ•°æ® (12 ç»´)
float input[12] = {
    0.1f, 0.2f, 0.3f,  // Gyro
    0.0f, 0.0f, 9.8f,  // Accel
    0.0f, 0.0f, 0.0f,  // Gyro prev
    1.2f,              // Current
    0.5f,              // Error
    0.0f               // Reserved
};

// 3. æ‰§è¡Œæ¨ç†
float output[1];
Inference_Run(ctx, input, output);

printf("è¾“å‡º: %.3f\n", output[0]);

// 4. æ¸…ç†
Inference_DestroyContext(ctx);
```

### æ€§èƒ½ç›‘æ§

```c
// è·å–æ¨ç†ç»Ÿè®¡
uint32_t avg_time_us;
float fps;
Inference_GetStats(ctx, &avg_time_us, &fps);

printf("å¹³å‡å»¶è¿Ÿ: %lu Î¼s\n", avg_time_us);
printf("æ¨ç†é€Ÿç‡: %.1f FPS\n", fps);

// è·å– CIM æ€§èƒ½
CIM_PerfStats_t stats;
CIM_GetPerfStats(&stats);
printf("GOPS: %.2f\n", stats.gops);
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ¨¡å‹æ ¼å¼

å¦‚æœä½ éœ€è¦è‡ªå®šä¹‰æ¨¡å‹æ ¼å¼ï¼Œä¿®æ”¹ `tools/flash_model.py`:

```python
# è‡ªå®šä¹‰é…ç½®
config = {
    'input_size': 24,      # å¢åŠ è¾“å…¥ç»´åº¦
    'output_size': 4,      # å¤šè¾“å‡º
    'hidden_size': 32,     # æ›´å¤§çš„éšè—å±‚
    'num_layers': 5,       # æ›´æ·±çš„ç½‘ç»œ
    'dtype': 0,            # INT8
    'has_lstm': 1,         # åŒ…å« LSTM
    'quant_scale': 0.1,
    'quant_zero': 128
}
```

### è¿è¡Œæ—¶æ›´æ–°æ¨¡å‹

```c
// ä»æ–°åœ°å€åŠ è½½æ¨¡å‹
Model_Unload(&model);
Model_LoadFromFlash(MODEL_CUSTOM, &model);
Model_LoadToCIM(&model, 0);

// é‡æ–°åˆ›å»ºæ¨ç†ä¸Šä¸‹æ–‡
Inference_DestroyContext(ctx);
ctx = Inference_CreateContext(&model);
```

### LSTM çŠ¶æ€ç®¡ç†

```c
// é‡ç½® LSTM çŠ¶æ€ (å¼€å§‹æ–°åºåˆ—)
Inference_ResetState(ctx);

// æŒç»­æ¨ç† (ä¿æŒ LSTM çŠ¶æ€)
for (int i = 0; i < 100; i++) {
    Inference_Run(ctx, input, output);
    // LSTM çŠ¶æ€è‡ªåŠ¨æ›´æ–°
}
```

## ğŸ“Š æ¨¡å‹æ–‡ä»¶æ ¼å¼

### FLASH å¸ƒå±€

```
æ¨¡å‹æ–‡ä»¶ç»“æ„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” 0x0000
â”‚ Header (128B)    â”‚
â”‚  - Magic         â”‚
â”‚  - Version       â”‚
â”‚  - Offsets       â”‚
â”‚  - CRC32         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Config (32B)     â”‚
â”‚  - Input size    â”‚
â”‚  - Output size   â”‚
â”‚  - Hidden size   â”‚
â”‚  - Quant params  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Weights (xKB)    â”‚
â”‚  - Layer 1       â”‚
â”‚  - Layer 2       â”‚
â”‚  - ...           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¤´éƒ¨ç»“æ„

```c
typedef struct {
    uint32_t magic;         // 0x43494D32 ("CIM2")
    uint16_t version;       // 0x0200 (v2.0)
    uint16_t reserved;
    uint32_t model_size;    // æ€»å¤§å°
    uint32_t weight_offset; // æƒé‡åç§»
    uint32_t weight_size;   // æƒé‡å¤§å°
    uint32_t config_offset; // é…ç½®åç§»
    uint32_t config_size;   // é…ç½®å¤§å°
    uint32_t crc32;         // CRC32 æ ¡éªŒ
    char model_name[32];    // æ¨¡å‹åç§°
    char model_hash[64];    // SHA-256 å“ˆå¸Œ
} ModelHeader_t;
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–

### ä¼˜åŒ–æ¨ç†é€Ÿåº¦

1. **ä½¿ç”¨ INT8 é‡åŒ–**
   ```bash
   python reflex_net_v2.py --quantize
   ```

2. **ä¼˜åŒ– CIM Bank åˆ†é…**
   ```c
   // é¢„åŠ è½½å¤šä¸ªæ¨¡å‹åˆ°ä¸åŒ Bank
   Model_LoadToCIM(&model1, 0);
   Model_LoadToCIM(&model2, 1);
   ```

3. **å¯ç”¨ CIM ä¸­æ–­æ¨¡å¼**
   ```c
   CIM_EnableIRQ(true);
   // æ¨ç†åœ¨åå°è¿è¡Œ,ä¸é˜»å¡ä¸»å¾ªç¯
   ```

### å‡å°‘åŠŸè€—

```c
// å¯ç”¨ç”µæºç®¡ç†
Power_EnableAutoMode(100);

// æ¨ç†é—´éš™è‡ªåŠ¨è¿›å…¥ä½åŠŸè€—
while(1) {
    Inference_Run(ctx, input, output);
    Delay_ms(10);  // 100Hz æ¨ç†
    Power_Update();  // è‡ªåŠ¨é™ä½åŠŸè€—
}
```

## ğŸ› æ•…éšœæ’é™¤

### æ¨¡å‹åŠ è½½å¤±è´¥

**é—®é¢˜**: `Model_LoadFromFlash` è¿”å› -1

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥ FLASH åœ°å€æ˜¯å¦æ­£ç¡®
2. éªŒè¯æ¨¡å‹æ˜¯å¦å·²çƒ§å½•
3. æ£€æŸ¥ CRC32 æ ¡éªŒ

### æ¨ç†è¾“å‡ºå¼‚å¸¸

**é—®é¢˜**: è¾“å‡ºå€¼ä¸åˆç†

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥è¾“å…¥æ•°æ®èŒƒå›´
2. éªŒè¯é‡åŒ–å‚æ•°
3. é‡ç½® LSTM çŠ¶æ€

### æ€§èƒ½ä¸è¾¾é¢„æœŸ

**é—®é¢˜**: æ¨ç†å»¶è¿Ÿè¿‡é«˜

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®è®¤ CIM å·²æ­£ç¡®åˆå§‹åŒ–
2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½åˆ° CIM SRAM
3. ç›‘æ§ `CIM_GetPerfStats()` è¾“å‡º

## ğŸ“š å‚è€ƒ

- [implementation_plan.md](file:///C:/Users/%E8%8D%A3%E8%80%80/.gemini/antigravity/brain/fcf659df-124f-41ad-9fe7-b48e2742b793/implementation_plan.md) - æŠ€æœ¯æ–¹æ¡ˆ
- [SDK_GUIDE.md](../SDK_GUIDE.md) - SDK æ–‡æ¡£
- [example_reflex_inference.c](../examples/example_reflex_inference.c) - å®Œæ•´ç¤ºä¾‹

---

**ç‰ˆæœ¬**: 2.0  
**æ›´æ–°**: 2026-01-19
