#!/usr/bin/env python3
"""
ç¨€ç–ä¼˜åŒ–å™¨ - MLIR ç¼–è¯‘å™¨ç¨€ç–æ”¯æŒæ¨¡å—
åˆ†æå’Œä¼˜åŒ–ç¨€ç–ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç”Ÿæˆç¨€ç– CIM æŒ‡ä»¤

@file sparsity_optimizer.py
@version 2.1.0
"""

import numpy as np
import onnx
from onnx import numpy_helper
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class SparsityStats:
    """ç¨€ç–ç»Ÿè®¡ä¿¡æ¯"""
    layer_name: str
    total_elements: int
    zero_elements: int
    near_zero_elements: int  # æ¥è¿‘é›¶ (< threshold)
    sparsity_ratio: float
    recommended_mode: str  # 'dense', 'sparse', 'csr'


@dataclass
class SparseLayerConfig:
    """ç¨€ç–å±‚é…ç½®"""
    layer_name: str
    use_sparse: bool
    threshold: float
    format: str  # 'dense', 'csr', 'csc', 'coo'
    pruned_weights: Optional[np.ndarray] = None


class SparsityOptimizer:
    """
    ç¨€ç–ä¼˜åŒ–å™¨
    
    åŠŸèƒ½ï¼š
    - æ¨¡å‹ç¨€ç–åº¦åˆ†æ
    - æƒé‡å‰ªæ
    - ç¨€ç–æ ¼å¼è½¬æ¢
    - ç¨€ç– CIM æŒ‡ä»¤ç”Ÿæˆ
    """
    
    def __init__(self, threshold: float = 0.01, prune_ratio: float = 0.0):
        """
        åˆå§‹åŒ–ç¨€ç–ä¼˜åŒ–å™¨
        
        Args:
            threshold: è¿‘é›¶é˜ˆå€¼ï¼ˆ|value| < threshold è§†ä¸ºé›¶ï¼‰
            prune_ratio: ç›®æ ‡å‰ªææ¯”ä¾‹ (0.0 = ä¸å‰ªæ, 0.5 = å‰ªæ 50%)
        """
        self.threshold = threshold
        self.prune_ratio = prune_ratio
        self.stats: Dict[str, SparsityStats] = {}
        self.layer_configs: Dict[str, SparseLayerConfig] = {}
    
    def analyze_sparsity(self, model_path: str) -> Dict[str, SparsityStats]:
        """
        åˆ†æ ONNX æ¨¡å‹çš„ç¨€ç–åº¦
        
        Args:
            model_path: ONNX æ¨¡å‹è·¯å¾„
            
        Returns:
            å„å±‚çš„ç¨€ç–ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info(f"ğŸ“Š åˆ†ææ¨¡å‹ç¨€ç–åº¦: {model_path}")
        
        model = onnx.load(model_path)
        self.stats = {}
        
        for initializer in model.graph.initializer:
            weights = numpy_helper.to_array(initializer)
            
            total = weights.size
            zeros = np.sum(weights == 0)
            near_zeros = np.sum(np.abs(weights) < self.threshold)
            sparsity = near_zeros / total if total > 0 else 0.0
            
            # æ¨èæ¨¡å¼
            if sparsity > 0.7:
                mode = 'csr'  # é«˜ç¨€ç–åº¦ä½¿ç”¨ CSR
            elif sparsity > 0.3:
                mode = 'sparse'  # ä¸­ç­‰ç¨€ç–åº¦ä½¿ç”¨ç¨€ç–è®¡ç®—
            else:
                mode = 'dense'  # ä½ç¨€ç–åº¦ä½¿ç”¨å¯†é›†è®¡ç®—
            
            stats = SparsityStats(
                layer_name=initializer.name,
                total_elements=total,
                zero_elements=zeros,
                near_zero_elements=near_zeros,
                sparsity_ratio=sparsity,
                recommended_mode=mode
            )
            
            self.stats[initializer.name] = stats
            
            logger.info(f"  {initializer.name}: "
                       f"ç¨€ç–ç‡ {sparsity*100:.1f}%, "
                       f"æ¨èæ¨¡å¼: {mode}")
        
        return self.stats
    
    def prune_weights(self, model_path: str, output_path: str,
                     strategy: str = 'magnitude') -> Dict[str, SparseLayerConfig]:
        """
        æƒé‡å‰ªæ
        
        Args:
            model_path: è¾“å…¥æ¨¡å‹è·¯å¾„
            output_path: è¾“å‡ºæ¨¡å‹è·¯å¾„
            strategy: å‰ªæç­–ç•¥ ('magnitude', 'random', 'structured')
            
        Returns:
            å„å±‚çš„ç¨€ç–é…ç½®
        """
        logger.info(f"âœ‚ï¸  æƒé‡å‰ªæ: ç­–ç•¥={strategy}, ç›®æ ‡æ¯”ä¾‹={self.prune_ratio*100:.0f}%")
        
        model = onnx.load(model_path)
        self.layer_configs = {}
        
        for i, initializer in enumerate(model.graph.initializer):
            weights = numpy_helper.to_array(initializer)
            original_shape = weights.shape
            
            if self.prune_ratio > 0:
                # å¹…åº¦å‰ªæ
                if strategy == 'magnitude':
                    flat = weights.flatten()
                    threshold_value = np.percentile(np.abs(flat), 
                                                    self.prune_ratio * 100)
                    mask = np.abs(weights) >= threshold_value
                    pruned = weights * mask
                    
                # éšæœºå‰ªæ
                elif strategy == 'random':
                    mask = np.random.random(weights.shape) > self.prune_ratio
                    pruned = weights * mask
                    
                # ç»“æ„åŒ–å‰ªæï¼ˆé€šé“çº§ï¼‰
                elif strategy == 'structured':
                    if len(weights.shape) >= 2:
                        channel_norms = np.linalg.norm(weights, axis=tuple(range(1, len(weights.shape))))
                        threshold_value = np.percentile(channel_norms, 
                                                       self.prune_ratio * 100)
                        mask = channel_norms >= threshold_value
                        pruned = weights.copy()
                        pruned[~mask] = 0
                    else:
                        pruned = weights
                else:
                    pruned = weights
                    
                # è®¡ç®—å®é™…ç¨€ç–ç‡
                actual_sparsity = np.sum(pruned == 0) / pruned.size
                
                logger.info(f"  {initializer.name}: "
                           f"å‰ªæåç¨€ç–ç‡ {actual_sparsity*100:.1f}%")
            else:
                pruned = weights
                actual_sparsity = np.sum(weights == 0) / weights.size
            
            # å†³å®šæ ¼å¼
            if actual_sparsity > 0.7:
                format_type = 'csr'
            elif actual_sparsity > 0.3:
                format_type = 'sparse'
            else:
                format_type = 'dense'
            
            config = SparseLayerConfig(
                layer_name=initializer.name,
                use_sparse=(actual_sparsity > 0.3),
                threshold=self.threshold,
                format=format_type,
                pruned_weights=pruned
            )
            
            self.layer_configs[initializer.name] = config
            
            # æ›´æ–°æ¨¡å‹æƒé‡
            model.graph.initializer[i].CopyFrom(
                numpy_helper.from_array(pruned.astype(weights.dtype), 
                                       initializer.name)
            )
        
        onnx.save(model, output_path)
        logger.info(f"âœ“ å‰ªææ¨¡å‹å·²ä¿å­˜: {output_path}")
        
        return self.layer_configs
    
    def convert_to_csr(self, weights: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        å°†æƒé‡è½¬æ¢ä¸º CSR æ ¼å¼
        
        Args:
            weights: 2D æƒé‡çŸ©é˜µ
            
        Returns:
            (values, col_indices, row_ptr)
        """
        if len(weights.shape) != 2:
            # å±•å¹³é«˜ç»´å¼ é‡
            weights = weights.reshape(weights.shape[0], -1)
        
        values = []
        col_indices = []
        row_ptr = [0]
        
        for row in weights:
            for col_idx, val in enumerate(row):
                if val != 0:
                    values.append(val)
                    col_indices.append(col_idx)
            row_ptr.append(len(values))
        
        return (np.array(values), 
                np.array(col_indices, dtype=np.int16),
                np.array(row_ptr, dtype=np.int32))
    
    def generate_sparse_instructions(self, layer_config: SparseLayerConfig) -> List[Dict]:
        """
        ç”Ÿæˆç¨€ç– CIM æŒ‡ä»¤
        
        Args:
            layer_config: å±‚é…ç½®
            
        Returns:
            CIM æŒ‡ä»¤åˆ—è¡¨
        """
        instructions = []
        
        if not layer_config.use_sparse:
            # å¯†é›†æ¨¡å¼
            instructions.append({
                'opcode': 'CIM_DENSE_MATMUL',
                'sparse_enable': False,
                'threshold': 0
            })
            return instructions
        
        if layer_config.format == 'csr':
            # CSR ç¨€ç–æ¨¡å¼
            values, col_indices, row_ptr = self.convert_to_csr(
                layer_config.pruned_weights
            )
            
            instructions.append({
                'opcode': 'CIM_SPARSE_CSR_SETUP',
                'num_values': len(values),
                'row_count': len(row_ptr) - 1
            })
            
            instructions.append({
                'opcode': 'CIM_SPARSE_CSR_LOAD_VALUES',
                'data': values.tolist()
            })
            
            instructions.append({
                'opcode': 'CIM_SPARSE_CSR_LOAD_INDICES',
                'col_indices': col_indices.tolist(),
                'row_ptr': row_ptr.tolist()
            })
            
            instructions.append({
                'opcode': 'CIM_SPARSE_CSR_MATMUL',
                'sparse_enable': True
            })
            
        else:
            # åŠ¨æ€ç¨€ç–æ¨¡å¼ï¼ˆè·³è¿‡é›¶å€¼ï¼‰
            instructions.append({
                'opcode': 'CIM_SPARSE_MATMUL',
                'sparse_enable': True,
                'threshold': int(layer_config.threshold * 128)  # è½¬ä¸º int8 é˜ˆå€¼
            })
        
        return instructions
    
    def optimize_model(self, input_path: str, output_path: str,
                      enable_pruning: bool = True,
                      prune_strategy: str = 'magnitude') -> Dict:
        """
        å®Œæ•´çš„ç¨€ç–ä¼˜åŒ–æµç¨‹
        
        Args:
            input_path: è¾“å…¥æ¨¡å‹è·¯å¾„
            output_path: è¾“å‡ºæ¨¡å‹è·¯å¾„
            enable_pruning: æ˜¯å¦å¯ç”¨å‰ªæ
            prune_strategy: å‰ªæç­–ç•¥
            
        Returns:
            ä¼˜åŒ–æŠ¥å‘Š
        """
        logger.info("=" * 50)
        logger.info("ğŸš€ å¼€å§‹ç¨€ç–ä¼˜åŒ–")
        logger.info("=" * 50)
        
        # 1. åˆ†æåŸå§‹ç¨€ç–åº¦
        original_stats = self.analyze_sparsity(input_path)
        
        # 2. å‰ªæï¼ˆå¯é€‰ï¼‰
        if enable_pruning and self.prune_ratio > 0:
            layer_configs = self.prune_weights(input_path, output_path, 
                                              prune_strategy)
        else:
            # ä¸å‰ªæï¼Œç›´æ¥å¤åˆ¶
            import shutil
            shutil.copy(input_path, output_path)
            layer_configs = {}
        
        # 3. é‡æ–°åˆ†æ
        final_stats = self.analyze_sparsity(output_path)
        
        # 4. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        report = {
            'input_model': input_path,
            'output_model': output_path,
            'pruning_enabled': enable_pruning,
            'prune_ratio': self.prune_ratio,
            'prune_strategy': prune_strategy,
            'original_sparsity': {
                name: stats.sparsity_ratio 
                for name, stats in original_stats.items()
            },
            'final_sparsity': {
                name: stats.sparsity_ratio 
                for name, stats in final_stats.items()
            },
            'sparse_layers': sum(1 for s in final_stats.values() 
                                if s.recommended_mode != 'dense'),
            'estimated_speedup': self._estimate_speedup(final_stats)
        }
        
        logger.info("\n" + "=" * 50)
        logger.info("ğŸ“ˆ ä¼˜åŒ–æŠ¥å‘Š")
        logger.info("=" * 50)
        logger.info(f"  ç¨€ç–å±‚æ•°: {report['sparse_layers']}")
        logger.info(f"  é¢„ä¼°åŠ é€Ÿ: {report['estimated_speedup']:.2f}x")
        logger.info(f"  é¢„ä¼°åŠŸè€—é™ä½: {(1-1/report['estimated_speedup'])*100:.0f}%")
        
        return report
    
    def _estimate_speedup(self, stats: Dict[str, SparsityStats]) -> float:
        """ä¼°ç®—åŠ é€Ÿæ¯”"""
        if not stats:
            return 1.0
        
        total_elements = sum(s.total_elements for s in stats.values())
        skipped_elements = sum(s.near_zero_elements for s in stats.values())
        
        if total_elements == 0:
            return 1.0
        
        # ç®€åŒ–æ¨¡å‹ï¼šè·³è¿‡çš„æ“ä½œç›´æ¥è½¬åŒ–ä¸ºåŠ é€Ÿ
        # å®é™…éœ€è¦è€ƒè™‘ç´¢å¼•å¼€é”€
        skip_ratio = skipped_elements / total_elements
        overhead = 0.1  # 10% ç´¢å¼•å¼€é”€
        
        effective_skip = skip_ratio * (1 - overhead)
        speedup = 1 / (1 - effective_skip) if effective_skip < 1 else 10.0
        
        return min(speedup, 5.0)  # æœ€å¤§ 5x


def analyze_model_sparsity(model_path: str, threshold: float = 0.01) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†ææ¨¡å‹ç¨€ç–åº¦
    """
    optimizer = SparsityOptimizer(threshold=threshold)
    return optimizer.analyze_sparsity(model_path)


def prune_model(input_path: str, output_path: str, 
               prune_ratio: float = 0.3,
               strategy: str = 'magnitude') -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šå‰ªææ¨¡å‹
    """
    optimizer = SparsityOptimizer(prune_ratio=prune_ratio)
    return optimizer.prune_weights(input_path, output_path, strategy)


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç¨€ç–ä¼˜åŒ–å™¨')
    parser.add_argument('--model', required=True, help='è¾“å…¥ ONNX æ¨¡å‹')
    parser.add_argument('--output', help='è¾“å‡ºæ¨¡å‹è·¯å¾„')
    parser.add_argument('--analyze', action='store_true', help='ä»…åˆ†æç¨€ç–åº¦')
    parser.add_argument('--prune', action='store_true', help='å¯ç”¨å‰ªæ')
    parser.add_argument('--prune-ratio', type=float, default=0.3, 
                       help='å‰ªææ¯”ä¾‹ (0.0-1.0)')
    parser.add_argument('--threshold', type=float, default=0.01,
                       help='è¿‘é›¶é˜ˆå€¼')
    parser.add_argument('--strategy', default='magnitude',
                       choices=['magnitude', 'random', 'structured'],
                       help='å‰ªæç­–ç•¥')
    
    args = parser.parse_args()
    
    optimizer = SparsityOptimizer(
        threshold=args.threshold,
        prune_ratio=args.prune_ratio
    )
    
    if args.analyze:
        # ä»…åˆ†æ
        stats = optimizer.analyze_sparsity(args.model)
        print("\nç¨€ç–åº¦åˆ†æç»“æœ:")
        for name, s in stats.items():
            print(f"  {name}: {s.sparsity_ratio*100:.1f}% ({s.recommended_mode})")
    else:
        # å®Œæ•´ä¼˜åŒ–
        if not args.output:
            args.output = args.model.replace('.onnx', '_sparse.onnx')
        
        report = optimizer.optimize_model(
            args.model, args.output,
            enable_pruning=args.prune,
            prune_strategy=args.strategy
        )
        
        print(f"\nâœ… ä¼˜åŒ–å®Œæˆ! è¾“å‡º: {args.output}")
        print(f"   é¢„ä¼°åŠ é€Ÿ: {report['estimated_speedup']:.2f}x")


if __name__ == '__main__':
    main()
