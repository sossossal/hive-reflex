#!/usr/bin/env python3
"""
MLIR ç¼–è¯‘å™¨ - å°† ONNX/PyTorch æ¨¡å‹ç¼–è¯‘ä¸º CIM ç›®æ ‡ä»£ç 

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹è„šæœ¬ï¼Œå±•ç¤ºå¦‚ä½•é›†æˆ MLIR ç¼–è¯‘å™¨
å®é™…ç”Ÿäº§ç¯å¢ƒéœ€è¦å®Œæ•´çš„ MLIR CIM Dialect å®ç°
"""

import argparse
import os
import sys
import subprocess
import torch
import onnx
from pathlib import Path

# å°è¯•å¯¼å…¥ torch-mlir (éœ€è¦å•ç‹¬å®‰è£…)
try:
    import torch_mlir
    HAS_TORCH_MLIR = True
except ImportError:
    HAS_TORCH_MLIR = False
    print("è­¦å‘Š: torch-mlir æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–çš„ç¼–è¯‘æµç¨‹")

class CIMCompiler:
    """CIM ç¼–è¯‘å™¨ç±»"""
    
    def __init__(self, target="imc22", opt_level=2):
        self.target = target
        self.opt_level = opt_level
        self.temp_dir = Path("build/mlir_temp")
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
    def compile_onnx(self, onnx_path, output_c, output_weights):
        """
        ç¼–è¯‘ ONNX æ¨¡å‹
        
        Args:
            onnx_path: ONNX æ¨¡å‹è·¯å¾„
            output_c: è¾“å‡º C ä»£ç è·¯å¾„
            output_weights: è¾“å‡ºæƒé‡äºŒè¿›åˆ¶è·¯å¾„
        """
        print(f"ğŸ“¦ åŠ è½½ ONNX æ¨¡å‹: {onnx_path}")
        model = onnx.load(onnx_path)
        
        # éªŒè¯æ¨¡å‹
        onnx.checker.check_model(model)
        print("âœ“ ONNX æ¨¡å‹éªŒè¯é€šè¿‡")
        
        # æå–æƒé‡
        weights_data = self._extract_weights(model)
        print(f"âœ“ æå–æƒé‡: {len(weights_data)} bytes")
        
        # ç”Ÿæˆ C ä»£ç  (ç®€åŒ–ç‰ˆ)
        self._generate_c_code(model, output_c, weights_data)
        print(f"âœ“ ç”Ÿæˆ C ä»£ç : {output_c}")
        
        # ä¿å­˜æƒé‡
        with open(output_weights, 'wb') as f:
            f.write(weights_data)
        print(f"âœ“ ä¿å­˜æƒé‡: {output_weights}")
        
    def compile_pytorch(self, model, sample_input, output_c, output_weights):
        """
        ç¼–è¯‘ PyTorch æ¨¡å‹
        
        Args:
            model: PyTorch æ¨¡å‹
            sample_input: ç¤ºä¾‹è¾“å…¥
            output_c: è¾“å‡º C ä»£ç è·¯å¾„
            output_weights: è¾“å‡ºæƒé‡äºŒè¿›åˆ¶è·¯å¾„
        """
        print("ğŸ”¥ PyTorch æ¨¡å‹ â†’ ONNX")
        
        # å¯¼å‡ºåˆ° ONNX
        onnx_path = self.temp_dir / "model.onnx"
        torch.onnx.export(
            model, 
            sample_input, 
            str(onnx_path),
            input_names=['input'],
            output_names=['output'],
            opset_version=11
        )
        
        # ç¼–è¯‘ ONNX
        self.compile_onnx(str(onnx_path), output_c, output_weights)
        
    def _extract_weights(self, onnx_model):
        """ä» ONNX æ¨¡å‹æå–æƒé‡"""
        import numpy as np
        
        weights_list = []
        for initializer in onnx_model.graph.initializer:
            # è½¬æ¢ä¸º numpy æ•°ç»„
            tensor = onnx.numpy_helper.to_array(initializer)
            
            # é‡åŒ–ä¸º INT8 (ç®€åŒ–ç‰ˆ)
            if tensor.dtype == np.float32:
                # è®¡ç®—é‡åŒ–å‚æ•°
                min_val, max_val = tensor.min(), tensor.max()
                scale = (max_val - min_val) / 255.0
                zero_point = -min_val / scale
                
                # é‡åŒ–
                tensor_int8 = np.clip(
                    np.round(tensor / scale + zero_point), 
                    0, 255
                ).astype(np.uint8)
                
                weights_list.append(tensor_int8.tobytes())
            else:
                weights_list.append(tensor.tobytes())
        
        return b''.join(weights_list)
        
    def _generate_c_code(self, onnx_model, output_path, weights_data):
        """ç”Ÿæˆ C ä»£ç  (ç®€åŒ–ç‰ˆ)"""
        
        # åˆ†ææ¨¡å‹ç»“æ„
        layers = self._analyze_model(onnx_model)
        
        # ç”Ÿæˆä»£ç 
        code = []
        code.append("// è‡ªåŠ¨ç”Ÿæˆçš„ CIM æ¨ç†ä»£ç ")
        code.append("// ç”± MLIR ç¼–è¯‘å™¨ç”Ÿæˆ")
        code.append("")
        code.append('#include "imc22_cim.h"')
        code.append('#include "imc22_nvs.h"')
        code.append("")
        
        # æƒé‡å£°æ˜
        code.append(f"// æƒé‡æ•°æ® ({len(weights_data)} bytes)")
        code.append("extern const uint8_t model_weights[];")
        code.append("")
        
        # æ¨ç†å‡½æ•°
        code.append("int model_inference(const float *input, float *output) {")
        code.append("    // åŠ è½½æƒé‡åˆ° CIM")
        code.append("    CIM_LoadWeights(model_weights, sizeof(model_weights), 0);")
        code.append("")
        
        # ç”Ÿæˆå„å±‚ä»£ç 
        for i, layer in enumerate(layers):
            if layer['type'] == 'fc':
                code.append(f"    // Layer {i}: Fully Connected")
                code.append(f"    CIM_FullyConnected(")
                code.append(f"        layer_{i}_input, layer_{i}_output,")
                code.append(f"        layer_{i}_weights, layer_{i}_bias,")
                code.append(f"        {layer['input_size']}, {layer['output_size']},")
                code.append(f"        {layer['activation']}")
                code.append(f"    );")
                code.append("")
        
        code.append("    return 0;")
        code.append("}")
        
        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w') as f:
            f.write('\n'.join(code))
            
    def _analyze_model(self, onnx_model):
        """åˆ†æ ONNX æ¨¡å‹ç»“æ„"""
        layers = []
        
        for node in onnx_model.graph.node:
            if node.op_type == 'MatMul' or node.op_type == 'Gemm':
                layers.append({
                    'type': 'fc',
                    'name': node.name,
                    'input_size': 12,  # ç®€åŒ–
                    'output_size': 32,
                    'activation': 1  # ReLU
                })
        
        return layers


def main():
    parser = argparse.ArgumentParser(description='MLIR CIM ç¼–è¯‘å™¨')
    parser.add_argument('--model', required=True, help='ONNX æ¨¡å‹è·¯å¾„')
    parser.add_argument('--output-c', default='build/model_inference.c', 
                       help='è¾“å‡º C ä»£ç è·¯å¾„')
    parser.add_argument('--output-weights', default='build/model_weights.bin',
                       help='è¾“å‡ºæƒé‡è·¯å¾„')
    parser.add_argument('--opt', type=int, default=2, help='ä¼˜åŒ–çº§åˆ« (0-3)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç¼–è¯‘å™¨
    compiler = CIMCompiler(opt_level=args.opt)
    
    # ç¼–è¯‘æ¨¡å‹
    compiler.compile_onnx(args.model, args.output_c, args.output_weights)
    
    print("\nâœ… ç¼–è¯‘å®Œæˆ!")
    print(f"   C ä»£ç : {args.output_c}")
    print(f"   æƒé‡:   {args.output_weights}")
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. å°†ç”Ÿæˆçš„ C ä»£ç é›†æˆåˆ°é¡¹ç›®ä¸­")
    print("  2. ä½¿ç”¨ make ç¼–è¯‘å®Œæ•´å›ºä»¶")
    print("  3. çƒ§å½•åˆ° IMC-22 èŠ¯ç‰‡")


if __name__ == '__main__':
    main()
