#!/usr/bin/env python3
"""
CIM ä»£ç ç”Ÿæˆå™¨ - é’ˆå¯¹ Digital CIM æ¶æ„ä¼˜åŒ–çš„ä»£ç ç”Ÿæˆ
"""

import onnx
from onnx import numpy_helper
import numpy as np
from typing import List, Dict

class CIMCodeGenerator:
    """CIM ç›®æ ‡ä»£ç ç”Ÿæˆå™¨"""
    
    def __init__(self, model):
        self.model = model
        self.graph = model.graph
        self.layer_count = 0
        self.code_lines = []
        
    def generate(self, output_c: str, output_weights: str, output_config: str):
        """
        ç”Ÿæˆ CIM ä¼˜åŒ–çš„ C ä»£ç 
        
        Args:
            output_c: C ä»£ç è¾“å‡ºè·¯å¾„
            output_weights: æƒé‡äºŒè¿›åˆ¶è¾“å‡ºè·¯å¾„
            output_config: é…ç½®JSONè¾“å‡ºè·¯å¾„
        """
        print("ğŸ”¨ CIM ä»£ç ç”Ÿæˆå™¨")
        print("=" * 50)
        
        # åˆ†ææ¨¡å‹ç»“æ„
        layers = self._analyze_graph()
        print(f"âœ“ åˆ†ææ¨¡å‹: {len(layers)} å±‚")
        
        # ç”Ÿæˆä»£ç 
        self._generate_header()
        self._generate_inference_function(layers)
        self._generate_footer()
        
        # å†™å…¥æ–‡ä»¶
        with open(output_c, 'w') as f:
            f.write('\n'.join(self.code_lines))
        
        print(f"âœ“ ç”Ÿæˆ C ä»£ç : {output_c}")
        
        # å¯¼å‡ºæƒé‡
        weights_data = self._export_weights()
        with open(output_weights, 'wb') as f:
            f.write(weights_data)
        
        print(f"âœ“ å¯¼å‡ºæƒé‡: {output_weights} ({len(weights_data)} bytes)")
        
        # ç”Ÿæˆé…ç½®
        config = self._generate_config(layers)
        import json
        with open(output_config, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"âœ“ ç”Ÿæˆé…ç½®: {output_config}")
        
        return output_c
    
    def _analyze_graph(self) -> List[Dict]:
        """åˆ†æè®¡ç®—å›¾ï¼Œæå–å±‚ä¿¡æ¯"""
        layers = []
        
        for node in self.graph.node:
            layer = {
                'name': node.name or f"layer_{len(layers)}",
                'op_type': node.op_type,
                'inputs': list(node.input),
                'outputs': list(node.output),
            }
            
            # æå–å±æ€§
            if node.op_type == 'Gemm' or node.op_type == 'MatMul':
                layer['type'] = 'fc'
                # ä» initializer è·å–å½¢çŠ¶
                for init in self.graph.initializer:
                    if init.name in node.input:
                        weights = numpy_helper.to_array(init)
                        layer['shape'] = weights.shape
            
            elif node.op_type == 'LSTM':
                layer['type'] = 'lstm'
                # è·å– LSTM å‚æ•°
                for attr in node.attribute:
                    if attr.name == 'hidden_size':
                        layer['hidden_size'] = attr.i
            
            elif node.op_type == 'Relu' or node.op_type.endswith('Relu'):
                layer['type'] = 'activation'
                layer['activation'] = 'relu'
            
            elif node.op_type == 'Tanh':
                layer['type'] = 'activation'
                layer['activation'] = 'tanh'
            
            layers.append(layer)
        
        return layers
    
    def _generate_header(self):
        """ç”Ÿæˆä»£ç å¤´éƒ¨"""
        self.code_lines.extend([
            "/**",
            " * è‡ªåŠ¨ç”Ÿæˆçš„ CIM æ¨ç†ä»£ç ",
            " * ç”± MLIR ç¼–è¯‘å™¨ç”Ÿæˆ",
            " */",
            "",
            '#include "imc22_cim.h"',
            '#include "model_loader.h"',
            '#include <string.h>',
            "",
            "// æƒé‡æ•°æ® (åœ¨ FLASH ä¸­)",
            "extern const uint8_t model_weights[];",
            "extern const uint32_t model_weights_size;",
            "",
        ])
    
    def _generate_inference_function(self, layers: List[Dict]):
        """ç”Ÿæˆæ¨ç†å‡½æ•°"""
        self.code_lines.extend([
            "/**",
            " * @brief æ¨¡å‹æ¨ç†å‡½æ•°",
            " * @param input è¾“å…¥æ•°æ®",
            " * @param output è¾“å‡ºæ•°æ®",
            " * @param context æ¨ç†ä¸Šä¸‹æ–‡",
            " * @return 0 æˆåŠŸ, -1 å¤±è´¥",
            " */",
            "int model_inference_optimized(const float *input, float *output, void *context) {",
            "    InferenceContext_t *ctx = (InferenceContext_t*)context;",
            "    ",
            "    // ä¸´æ—¶ç¼“å†²åŒº",
            "    float *temp1 = ctx->temp_buffer;",
            f"    float *temp2 = temp1 + {self._estimate_buffer_size(layers)};",
            "    ",
        ])
        
        # ä¸ºæ¯ä¸€å±‚ç”Ÿæˆä»£ç 
        input_var = "input"
        
        for i, layer in enumerate(layers):
            output_var = "output" if i == len(layers) - 1 else f"temp{(i % 2) + 1}"
            
            if layer['type'] == 'fc':
                self._generate_fc_layer(layer, input_var, output_var, i)
            elif layer['type'] == 'lstm':
                self._generate_lstm_layer(layer, input_var, output_var, i)
            elif layer['type'] == 'activation':
                self._generate_activation(layer, input_var, output_var)
            
            input_var = output_var
        
        self.code_lines.extend([
            "    ",
            "    return 0;",
            "}",
            "",
        ])
    
    def _generate_fc_layer(self, layer: Dict, input_var: str, output_var: str, idx: int):
        """ç”Ÿæˆå…¨è¿æ¥å±‚ä»£ç """
        self.code_lines.extend([
            f"    // Layer {idx}: å…¨è¿æ¥ ({layer.get('shape', 'unknown')})",
            f"    {{",
            f"        const float *weights = (const float*)(model_weights + weight_offset_{idx});",
            f"        const float *bias = weights + {layer.get('shape', [0,0])[0] * layer.get('shape', [0,0])[1]};",
            f"        ",
            f"        // ä½¿ç”¨ CIM åŠ é€Ÿ",
            f"        CIM_FullyConnected(",
            f"            {input_var}, {output_var},",
            f"            weights, bias,",
            f"            {layer.get('shape', [0,0])[1]}, {layer.get('shape', [0,0])[0]},",
            f"            {1 if 'Relu' in layer.get('op_type', '') else 0}  // æ¿€æ´»å‡½æ•°",
            f"        );",
            f"    }}",
            "    ",
        ])
    
    def _generate_lstm_layer(self, layer: Dict, input_var: str, output_var: str, idx: int):
        """ç”Ÿæˆ LSTM å±‚ä»£ç """
        hidden_size = layer.get('hidden_size', 16)
        
        self.code_lines.extend([
            f"    // Layer {idx}: LSTM (hidden={hidden_size})",
            f"    {{",
            f"        const float *weights = (const float*)(model_weights + weight_offset_{idx});",
            f"        ",
            f"        // ä½¿ç”¨ CIM LSTM åŠ é€Ÿå™¨",
            f"        CIM_LSTM(",
            f"            {input_var},",
            f"            ctx->lstm_h,",
            f"            ctx->lstm_c,",
            f"            ctx->lstm_h,  // æ›´æ–°éšè—çŠ¶æ€",
            f"            ctx->lstm_c,  // æ›´æ–°ç»†èƒçŠ¶æ€",
            f"            (void*)weights",
            f"        );",
            f"        ",
            f"        // å¤åˆ¶è¾“å‡º",
            f"        memcpy({output_var}, ctx->lstm_h, {hidden_size} * sizeof(float));",
            f"    }}",
            "    ",
        ])
    
    def _generate_activation(self, layer: Dict, input_var: str, output_var: str):
        """ç”Ÿæˆæ¿€æ´»å‡½æ•°ä»£ç """
        act_type = layer.get('activation', 'relu')
        
        if input_var != output_var:
            self.code_lines.append(f"    memcpy({output_var}, {input_var}, layer_size * sizeof(float));")
        
        if act_type == 'relu':
            self.code_lines.append(f"    CIM_ReLU({output_var}, layer_size);")
        elif act_type == 'tanh':
            self.code_lines.append(f"    CIM_Tanh({output_var}, layer_size);")
        
        self.code_lines.append("    ")
    
    def _generate_footer(self):
        """ç”Ÿæˆä»£ç å°¾éƒ¨"""
        self.code_lines.extend([
            "// æƒé‡åç§»é‡ (è‡ªåŠ¨è®¡ç®—)",
            "const uint32_t weight_offset_0 = 0;",
            "// ... (å…¶ä»–å±‚çš„åç§»)",
            "",
        ])
    
    def _export_weights(self) -> bytes:
        """å¯¼å‡ºæƒé‡ä¸ºäºŒè¿›åˆ¶"""
        weights_list = []
        
        for init in self.graph.initializer:
            tensor = numpy_helper.to_array(init)
            
            # è½¬æ¢ä¸º INT8 (ç®€åŒ–ç‰ˆ)
            if tensor.dtype == np.float32:
                scale = max(abs(tensor.min()), abs(tensor.max())) / 127.0
                tensor_int8 = np.clip(tensor / scale, -128, 127).astype(np.int8)
                weights_list.append(tensor_int8.tobytes())
            else:
                weights_list.append(tensor.tobytes())
        
        return b''.join(weights_list)
    
    def _generate_config(self, layers: List[Dict]) -> Dict:
        """ç”Ÿæˆæ¨¡å‹é…ç½®"""
        return {
            'model_name': 'optimized_model',
            'num_layers': len(layers),
            'layers': [
                {
                    'name': layer['name'],
                    'type': layer['type'],
                    'shape': str(layer.get('shape', 'unknown'))
                }
                for layer in layers
            ]
        }
    
    def _estimate_buffer_size(self, layers: List[Dict]) -> int:
        """ä¼°è®¡ç¼“å†²åŒºå¤§å°"""
        max_size = 0
        
        for layer in layers:
            if 'shape' in layer:
                size = max(layer['shape'])
                max_size = max(max_size, size)
        
        return max_size or 256


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CIM ä»£ç ç”Ÿæˆå™¨')
    parser.add_argument('--model', required=True, help='ONNX æ¨¡å‹è·¯å¾„')
    parser.add_argument('--output-c', default='generated_inference.c', help='C ä»£ç è¾“å‡º')
    parser.add_argument('--output-weights', default='generated_weights.bin', help='æƒé‡è¾“å‡º')
    parser.add_argument('--output-config', default='model_config.json', help='é…ç½®è¾“å‡º')
    
    args = parser.parse_args()
    
    model = onnx.load(args.model)
    generator = CIMCodeGenerator(model)
    generator.generate(args.output_c, args.output_weights, args.output_config)
    
    print("\nâœ… ä»£ç ç”Ÿæˆå®Œæˆ!")


if __name__ == '__main__':
    main()
